stages:
  preprocess:
    cmd: python -m src.preprocess --in data/raw/restaurants.csv --out data/interim/clean.csv
    deps:
      - src/preprocess.py
      - data/raw/restaurants.csv
    outs:
      - data/interim/clean.csv

  feature_engineering:
    cmd: python -m src.feature_engineering --in data/interim/clean.csv --out data/processed/features.parquet
    deps:
      - src/feature_engineering.py
      - data/interim/clean.csv
    outs:
      - data/processed/features.parquet

  Predictive_modelling:
    # Runs both sklearn models (regression + classification)
    cmd: >
      python -m src.train_regression --in data/processed/features.parquet --out models/regression.pkl --metrics metrics/regression.json
      && python -m src.train_classification --in data/processed/features.parquet --out models/classifier.pkl --metrics metrics/classification.json
    deps:
      - src/train_regression.py
      - src/train_classification.py
      - data/processed/features.parquet
    outs:
      - models/regression.pkl
      - models/classifier.pkl
    metrics:
      - metrics/regression.json
      - metrics/classification.json

  PySpark:
    # If your src/PySpark.py already runs and prints metrics, great.
    # Here we ask it to write a JSON we can track as a metric.
    cmd: python -m src.PySpark --in data/processed/features.parquet --out metrics/pyspark.json
    deps:
      - src/PySpark.py
      - data/processed/features.parquet
    metrics:
      - metrics/pyspark.json
